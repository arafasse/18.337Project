{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "not implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization of weights (w/o batchnorm)\n",
    "function init_model()\n",
    "    w =  map(atype, Any[ xavier(Float64,3,3,2,64),  zeros(Float64,1,1,64,1), # conv_1_1\n",
    "            xavier(Float64,3,3,64,64), zeros(Float64,1,1,64,1), # conv_1_2\n",
    "            xavier(Float64,3,3,64,128), zeros(Float64,1,1,128,1), # conv_2_1\n",
    "            xavier(Float64,3,3,128,128), zeros(Float64,1,1,128,1) , # conv_2_2\n",
    "            xavier(Float64,3,3,128,256), zeros(Float64,1,1,256,1), # conv_3_1 \n",
    "            xavier(Float64,3,3,256,256), zeros(Float64,1,1,256,1), # conv_3_2\n",
    "            xavier(Float64,3,3,256,512), zeros(Float64,1,1,512,1), # conv_4_1 \n",
    "            xavier(Float64,3,3,512,512), zeros(Float64,1,1,512,1),  # conv_4_2\n",
    "            xavier(Float64,3,3,768,256), zeros(Float64,1,1,256,1), #conv_5_1\n",
    "            xavier(Float64,3,3,256,256), zeros(Float64,1,1,256,1), # conv_5_2\n",
    "            xavier(Float64,3,3,384,128), zeros(Float64,1,1,128,1), # conv_6_1\n",
    "            xavier(Float64,3,3,128,128), zeros(Float64,1,1,128,1), # conv_6_2\n",
    "            xavier(Float64,3,3,192,64), zeros(Float64,1,1,64,1), # conv_7_1\n",
    "            xavier(Float64,3,3,64,64), zeros(Float64,1,1,64,1), # conv_7_2\n",
    "            xavier(Float64,1,1,64,2), zeros(Float64,1,1,2,1)]); # conv_7_3\n",
    "    return w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization of weights (w/o batchnorm)\n",
    "function init_model(depth, max_channels)\n",
    "    # initialize w\n",
    "    for layer in range(1,depth)\n",
    "        \n",
    "    w =  map(atype, Any[ xavier(Float64,3,3,2,64),  zeros(Float64,1,1,64,1), # conv_1_1\n",
    "            xavier(Float64,3,3,64,64), zeros(Float64,1,1,64,1), # conv_1_2\n",
    "            xavier(Float64,3,3,64,128), zeros(Float64,1,1,128,1), # conv_2_1\n",
    "            xavier(Float64,3,3,128,128), zeros(Float64,1,1,128,1) , # conv_2_2\n",
    "            xavier(Float64,3,3,128,256), zeros(Float64,1,1,256,1), # conv_3_1 \n",
    "            xavier(Float64,3,3,256,256), zeros(Float64,1,1,256,1), # conv_3_2\n",
    "            xavier(Float64,3,3,256,512), zeros(Float64,1,1,512,1), # conv_4_1 \n",
    "            xavier(Float64,3,3,512,512), zeros(Float64,1,1,512,1),  # conv_4_2\n",
    "            xavier(Float64,3,3,768,256), zeros(Float64,1,1,256,1), #conv_5_1\n",
    "            xavier(Float64,3,3,256,256), zeros(Float64,1,1,256,1), # conv_5_2\n",
    "            xavier(Float64,3,3,384,128), zeros(Float64,1,1,128,1), # conv_6_1\n",
    "            xavier(Float64,3,3,128,128), zeros(Float64,1,1,128,1), # conv_6_2\n",
    "            xavier(Float64,3,3,192,64), zeros(Float64,1,1,64,1), # conv_7_1\n",
    "            xavier(Float64,3,3,64,64), zeros(Float64,1,1,64,1), # conv_7_2\n",
    "            xavier(Float64,1,1,64,2), zeros(Float64,1,1,2,1)]); # conv_7_3\n",
    "    return w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization of weights (w/ batchnorm)\n",
    "function init_model_bn()\n",
    "    # include m (moments for batchnorm)\n",
    "    m = Any[bnmoments() for i = 1:n]# n = how often do we use BN?\n",
    "    \n",
    "    w =  map(atype, Any[ xavier(Float64,3,3,2,64),  zeros(Float64,1,1,64,1), # conv_1_1\n",
    "            xavier(Float64,3,3,64,64), zeros(Float64,1,1,64,1), # conv_1_2\n",
    "            xavier(Float64,3,3,64,128), zeros(Float64,1,1,128,1), # conv_2_1\n",
    "            xavier(Float64,3,3,128,128), zeros(Float64,1,1,128,1) , # conv_2_2\n",
    "            xavier(Float64,3,3,128,256), zeros(Float64,1,1,256,1), # conv_3_1 \n",
    "            xavier(Float64,3,3,256,256), zeros(Float64,1,1,256,1), # conv_3_2\n",
    "            xavier(Float64,3,3,256,512), zeros(Float64,1,1,512,1), # conv_4_1 \n",
    "            xavier(Float64,3,3,512,512), zeros(Float64,1,1,512,1),  # conv_4_2\n",
    "            xavier(Float64,3,3,768,256), zeros(Float64,1,1,256,1), #conv_5_1\n",
    "            xavier(Float64,3,3,256,256), zeros(Float64,1,1,256,1), # conv_5_2\n",
    "            xavier(Float64,3,3,384,128), zeros(Float64,1,1,128,1), # conv_6_1\n",
    "            xavier(Float64,3,3,128,128), zeros(Float64,1,1,128,1), # conv_6_2\n",
    "            xavier(Float64,3,3,192,64), zeros(Float64,1,1,64,1), # conv_7_1\n",
    "            xavier(Float64,3,3,64,64), zeros(Float64,1,1,64,1), # conv_7_2\n",
    "            xavier(Float64,1,1,64,2), zeros(Float64,1,1,2,1)]); # conv_7_3\n",
    "    return w, m\n",
    "    end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model\n",
    "IMPLEMENTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function predict(w,x_in)\n",
    "    \n",
    "    # TODO:\n",
    "    # include batch norm: https://github.com/denizyuret/Knet.jl/blob/master/src/batchnorm.jl\n",
    "    \n",
    "    # contraction\n",
    "    #block 1\n",
    "    # 256x256x2 -> 256x256x64\n",
    "    conv_1_1 = relu.(conv4(w[1],x_in, padding = 1) .+ w[2]) # bock 1 convolution 1\n",
    "    # 256x256x64 -> 256x256x64 (conc with block 7)\n",
    "    conv_1_2 = relu.(conv4(w[3],conv_1_1, padding = 1) .+ w[4]) # block 1 convolution 2, incl max pooling\n",
    "    # 256-256-64 -> 128x128x64\n",
    "    pool_1 = pool(conv_1_2)\n",
    "    \n",
    "    # block 2\n",
    "    # 128x128x64 -> 128x128x128\n",
    "    conv_2_1 = relu.(conv4(w[5],pool_1, padding = 1) .+ w[6])\n",
    "    # 128x128x128 -> 128x128x128 (conc with block 6)\n",
    "    conv_2_2 = relu.(conv4(w[7],conv_2_1, padding = 1) .+ w[8])\n",
    "    # 128x128x128 -> 64x64x128\n",
    "    pool_2 = pool(conv_2_2)\n",
    "    \n",
    "    #block 3\n",
    "    # 64x64x128 -> 64x64x256\n",
    "    conv_3_1 = relu.(conv4(w[9],pool_2, padding = 1) .+ w[10])\n",
    "    #64x64x256 -> 64x64x256\n",
    "    conv_3_2 = relu.(conv4(w[11],conv_3_1, padding = 1) .+ w[12])\n",
    "    # 64x64x256 -> 32x32x256 (conc with block 5)\n",
    "    pool_3 = pool(conv_3_2)\n",
    "    \n",
    "    # bottleneck \n",
    "    # block 4\n",
    "    # 32x32x256 -> 32x32x512\n",
    "    conv_4_1 = relu.(conv4(w[13], pool_3, padding = 1) .+ w[14])\n",
    "    #32x32x512 -> 32x32x512\n",
    "    conv_4_2 = relu.(conv4(w[15], conv_4_1, padding = 1) .+ w[16])\n",
    "    \n",
    "    # upsampling\n",
    "    # block 5\n",
    "    # upsampling/\"deconvolution\": 32x32x512 -> 64x64x512\n",
    "    upsampling_kernel_5 = convert(KnetArray, bilinear(Float64,2,2,512,512))\n",
    "    upsampling_5 = deconv4(upsampling_kernel_5, conv_4_2, padding = 1,stride = 2)\n",
    "    # concatenation with conv_3_2: 64x64x512 -> 64x64x768\n",
    "    conc_5 = convert(KnetArray,cat(convert(Array, upsampling_5), convert(Array, conv_3_2), dims = 3))\n",
    "    # 64x64x768 -> 64x64x256\n",
    "    conv_5_1 = relu.(conv4(w[17], conc_5, padding = 1) .+ w[18])\n",
    "    # 64x64x256-> 64x64x256\n",
    "    conv_5_2 = relu.(conv4(w[19], conv_5_1, padding = 1) .+ w[20])\n",
    "    \n",
    "    # block 6\n",
    "    # 64x64x256 -> 128x128x256\n",
    "    upsampling_kernel_6 = convert(KnetArray, bilinear(Float64,2,2,256,256))\n",
    "    upsampling_6 = deconv4(upsampling_kernel_6, conv_5_2, padding = 1,stride = 2) \n",
    "    # 128x128x256 -> 128x128x384\n",
    "    conc_6 = convert(KnetArray,cat(convert(Array,upsampling_6), convert(Array,conv_2_2), dims = 3)) # with conv_2_2\n",
    "    #128x128x384 -> 128x128x128\n",
    "    conv_6_1 = relu.(conv4(w[21], conc_6, padding = 1) .+ w[22])\n",
    "    # 128x128x128 -> 128x128x128\n",
    "    conv_6_2 = relu.(conv4(w[23], conv_6_1, padding = 1) .+ w[24])\n",
    "    \n",
    "    # block 7\n",
    "    # 128x128x128 -> 256x256x128\n",
    "    upsampling_kernel_7 = convert(KnetArray, bilinear(Float64,2,2,128,128))\n",
    "    upsampling_7 = deconv4(upsampling_kernel_7, conv_6_2, padding = 1,stride = 2) \n",
    "    # 256x256x128 -> 256x256x192\n",
    "    conc_7 = convert(KnetArray,cat(convert(Array, upsampling_7), convert(Array, conv_1_2), dims = 3))\n",
    "    # 256x256x192 -> 256x256x64\n",
    "    conv_7_1 = relu.(conv4(w[25], conc_7, padding = 1) .+ w[26])\n",
    "    # 256x256x64 -> 256x256x64\n",
    "    conv_7_2 = relu.(conv4(w[27], conv_7_1, padding = 1) .+ w[28])\n",
    "    # 256x256x64 -> 256x256x2 (1x1 convolution)\n",
    "    conv_7_3 = sigm.(conv4(w[29], conv_7_2).+ w[30])\n",
    "    \n",
    "    return conv_7_3\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss\n",
    "NOT IMPLEMENTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dice loss\n",
    "loss(w, x, ygold, predict) = nll(predict(w, x), ygold);\n",
    "lossgradient = grad(loss);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train\n",
    "NOT IMPLEMENTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function train(w, dtrn, optim, predict; epochs=10)\n",
    "    \n",
    "    for epoch = 1:epochs\n",
    "        for (x, y) in dtrn\n",
    "            g = lossgradient(w, x, y, predict)\n",
    "            update!(w, g, optim)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim(w; lr=0.1) = optimizers(w, Sgd;  lr=lr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function report(epoch, w, dtrn, dtst, predict)\n",
    "    println((:epoch, epoch, :trn, accuracy(w, dtrn, predict), :tst, accuracy(w, dtst, predict)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w   = initweights(atype);\n",
    "opt = optim(w);\n",
    "\n",
    "if fast\n",
    "    train(w, dtrn, opt, predict; epochs=nepochs)\n",
    "else\n",
    "    for epoch = 1:nepochs\n",
    "        train(w, dtrn, opt, predict; epochs=1)\n",
    "        report(epoch, w, dtrn, dtst, predict)\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.1",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
