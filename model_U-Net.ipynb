{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /Users/kathi/.julia/compiled/v1.0/Knet/f4vSz.ji for Knet [1902f260-5fb4-5aff-8c31-6271790ab950]\n",
      "└ @ Base loading.jl:1187\n",
      "WARNING: Method definition gcnode(AutoGrad.Node) in module AutoGrad at /Users/kathi/.julia/packages/AutoGrad/eAmjh/src/core.jl:38 overwritten in module Knet at /Users/kathi/.julia/packages/Knet/3lzCR/src/gcnode.jl:18.\n"
     ]
    }
   ],
   "source": [
    "using Knet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "not implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization of weights (w/o batchnorm)\n",
    "function init_model()\n",
    "    w =  map(KnetArray, Any[ xavier(Float64,3,3,2,64),  zeros(Float64,1,1,64,1), # conv_1_1\n",
    "            xavier(Float64,3,3,64,64), zeros(Float64,1,1,64,1), # conv_1_2\n",
    "            xavier(Float64,3,3,64,128), zeros(Float64,1,1,128,1), # conv_2_1\n",
    "            xavier(Float64,3,3,128,128), zeros(Float64,1,1,128,1) , # conv_2_2\n",
    "            xavier(Float64,3,3,128,256), zeros(Float64,1,1,256,1), # conv_3_1 \n",
    "            xavier(Float64,3,3,256,256), zeros(Float64,1,1,256,1), # conv_3_2\n",
    "            xavier(Float64,3,3,256,512), zeros(Float64,1,1,512,1), # conv_4_1 \n",
    "            xavier(Float64,3,3,512,512), zeros(Float64,1,1,512,1),  # conv_4_2\n",
    "            xavier(Float64,3,3,768,256), zeros(Float64,1,1,256,1), #conv_5_1\n",
    "            xavier(Float64,3,3,256,256), zeros(Float64,1,1,256,1), # conv_5_2\n",
    "            xavier(Float64,3,3,384,128), zeros(Float64,1,1,128,1), # conv_6_1\n",
    "            xavier(Float64,3,3,128,128), zeros(Float64,1,1,128,1), # conv_6_2\n",
    "            xavier(Float64,3,3,192,64), zeros(Float64,1,1,64,1), # conv_7_1\n",
    "            xavier(Float64,3,3,64,64), zeros(Float64,1,1,64,1), # conv_7_2\n",
    "            xavier(Float64,1,1,64,2), zeros(Float64,1,1,2,1)]); # conv_7_3\n",
    "    return w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization of weights (w/o batchnorm)\n",
    "function init_model(depth, max_channels)\n",
    "    # initialize w\n",
    "    for layer in range(1,depth)\n",
    "        \n",
    "    w =  map(atype, Any[ xavier(Float64,3,3,2,64),  zeros(Float64,1,1,64,1), # conv_1_1\n",
    "            xavier(Float64,3,3,64,64), zeros(Float64,1,1,64,1), # conv_1_2\n",
    "            xavier(Float64,3,3,64,128), zeros(Float64,1,1,128,1), # conv_2_1\n",
    "            xavier(Float64,3,3,128,128), zeros(Float64,1,1,128,1) , # conv_2_2\n",
    "            xavier(Float64,3,3,128,256), zeros(Float64,1,1,256,1), # conv_3_1 \n",
    "            xavier(Float64,3,3,256,256), zeros(Float64,1,1,256,1), # conv_3_2\n",
    "            xavier(Float64,3,3,256,512), zeros(Float64,1,1,512,1), # conv_4_1 \n",
    "            xavier(Float64,3,3,512,512), zeros(Float64,1,1,512,1),  # conv_4_2\n",
    "            xavier(Float64,3,3,768,256), zeros(Float64,1,1,256,1), #conv_5_1\n",
    "            xavier(Float64,3,3,256,256), zeros(Float64,1,1,256,1), # conv_5_2\n",
    "            xavier(Float64,3,3,384,128), zeros(Float64,1,1,128,1), # conv_6_1\n",
    "            xavier(Float64,3,3,128,128), zeros(Float64,1,1,128,1), # conv_6_2\n",
    "            xavier(Float64,3,3,192,64), zeros(Float64,1,1,64,1), # conv_7_1\n",
    "            xavier(Float64,3,3,64,64), zeros(Float64,1,1,64,1), # conv_7_2\n",
    "            xavier(Float64,1,1,64,2), zeros(Float64,1,1,2,1)]); # conv_7_3\n",
    "    return w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization of weights (w/ batchnorm)\n",
    "function init_model_bn()\n",
    "    # include m (moments for batchnorm)\n",
    "    m = Any[bnmoments() for i = 1:n]# n = how often do we use BN?\n",
    "    \n",
    "    w =  map(atype, Any[ xavier(Float64,3,3,2,64),  zeros(Float64,1,1,64,1), # conv_1_1\n",
    "            xavier(Float64,3,3,64,64), zeros(Float64,1,1,64,1), # conv_1_2\n",
    "            xavier(Float64,3,3,64,128), zeros(Float64,1,1,128,1), # conv_2_1\n",
    "            xavier(Float64,3,3,128,128), zeros(Float64,1,1,128,1) , # conv_2_2\n",
    "            xavier(Float64,3,3,128,256), zeros(Float64,1,1,256,1), # conv_3_1 \n",
    "            xavier(Float64,3,3,256,256), zeros(Float64,1,1,256,1), # conv_3_2\n",
    "            xavier(Float64,3,3,256,512), zeros(Float64,1,1,512,1), # conv_4_1 \n",
    "            xavier(Float64,3,3,512,512), zeros(Float64,1,1,512,1),  # conv_4_2\n",
    "            xavier(Float64,3,3,768,256), zeros(Float64,1,1,256,1), #conv_5_1\n",
    "            xavier(Float64,3,3,256,256), zeros(Float64,1,1,256,1), # conv_5_2\n",
    "            xavier(Float64,3,3,384,128), zeros(Float64,1,1,128,1), # conv_6_1\n",
    "            xavier(Float64,3,3,128,128), zeros(Float64,1,1,128,1), # conv_6_2\n",
    "            xavier(Float64,3,3,192,64), zeros(Float64,1,1,64,1), # conv_7_1\n",
    "            xavier(Float64,3,3,64,64), zeros(Float64,1,1,64,1), # conv_7_2\n",
    "            xavier(Float64,1,1,64,2), zeros(Float64,1,1,2,1)]); # conv_7_3\n",
    "    return w, m\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init_model (generic function with 6 methods)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function init_model(n_input_channels=1, n_output_channels=2, depth=4, max_channels=512, kernel_size=3)\n",
    "    w = Any[]\n",
    "    bn_params = Any[]\n",
    "    bn_moments = Any[bnmoments() for i = 1:14]\n",
    "    # 1st layer\n",
    "    # convolution\n",
    "    push!(w,xavier(Float64,kernel_size,kernel_size,n_input_channels,Int64(max_channels/(2^(depth-1)))))\n",
    "    # bias\n",
    "    push!(w,zeros(Float64,1,1,Int64(max_channels/(2^(depth-1))),1))\n",
    "    # batchnorm params\n",
    "    push!(bn_params, bnparams(Float64,Int64(max_channels/(2^(depth-1)))))\n",
    "    # convolution\n",
    "    push!(w,xavier(Float64,kernel_size,kernel_size,Int64(max_channels/(2^(depth-1))),Int64(max_channels/(2^(depth-1)))))\n",
    "    # bias\n",
    "    push!(w,zeros(Float64,1,1,Int64(max_channels/(2^(depth-1))),1))\n",
    "    push!(bn_params, bnparams(Float64,Int64(max_channels/(2^(depth-1)))))\n",
    "    \n",
    "    println(\"layer 1\")\n",
    "    println(size(w))\n",
    "    \n",
    "    # encoding arm: 2nd up to and including bottleneck\n",
    "    for layer=2:depth\n",
    "       push!(w,xavier(Float64,kernel_size,kernel_size,Int64(max_channels/(2^(depth-layer+1))),Int64(max_channels/(2^(depth-layer))))) \n",
    "        push!(w, zeros(Float64,1,1,Int64(max_channels/(2^(depth-layer))),1))\n",
    "        push!(bn_params, bnparams(Float64,Int64(max_channels/(2^(depth-layer)))))\n",
    "        push!(w,xavier(Float64,kernel_size,kernel_size,Int64(max_channels/(2^(depth-layer))),Int64(max_channels/(2^(depth-layer))))) \n",
    "        push!(w, zeros(Float64,1,1,Int64(max_channels/(2^(depth-layer))),1))\n",
    "        push!(bn_params, bnparams(Float64,Int64(max_channels/(2^(depth-layer)))))\n",
    "    end\n",
    "    \n",
    "    # decoding arm (except for 3rd convolution in the last layer)\n",
    "    for layer=(depth+1):(2*depth-1)\n",
    "        push!(w,xavier(Float64,kernel_size,kernel_size,Int64(1.5*max_channels/(2^(layer-depth-1))),Int64(max_channels/(2^(layer-depth))))) \n",
    "        push!(w, zeros(Float64,1,1,Int64(max_channels/(2^(layer-depth))),1))\n",
    "        push!(bn_params, bnparams(Float64,Int64(max_channels/(2^(layer-depth)))))\n",
    "        push!(w,xavier(Float64,kernel_size,kernel_size,Int64(max_channels/(2^(layer-depth))),Int64(max_channels/(2^(layer-depth))))) \n",
    "        push!(w, zeros(Float64,1,1,Int64(max_channels/(2^(layer-depth))),1))\n",
    "        push!(bn_params, bnparams(Float64,Int64(max_channels/(2^(layer-depth)))))\n",
    "    end\n",
    "    \n",
    "    # output convolution\n",
    "    push!(w, xavier(Float64,kernel_size,kernel_size,Int64(max_channels/(2^(depth-1))),n_output_channels)) \n",
    "    push!(w, zeros(Float64,1,1,n_output_channels,1))\n",
    "       \n",
    "    w = map(KnetArray, w)\n",
    "    bn_params = map(KnetArray, bn_params)\n",
    "    \n",
    "    return w, bn_moments, bn_params\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model\n",
    "IMPLEMENTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat3d_ (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cat3d_(arrs...)\n",
    "      H = size(first(arrs), 1)\n",
    "      W = size(first(arrs), 2)\n",
    "      C = sum(size(a, 3) for a in arrs)\n",
    "      T = size(first(arrs), 4)\n",
    "\n",
    "      @assert all(H == size(a, 1) for a in arrs)\n",
    "      @assert all(W == size(a, 2) for a in arrs)\n",
    "      @assert all(T == size(a, 4) for a in arrs)\n",
    "\n",
    "      out = Array{Float64}(undef, H, W, C, T)\n",
    "      curr = 1\n",
    "      for (i, A) in enumerate(arrs)\n",
    "        c = size(A, 3)\n",
    "        r = curr:(curr+c-1)\n",
    "        out[:, :, r, :] .= A\n",
    "        curr += c\n",
    "      end\n",
    "      out\n",
    "   end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function cat3d(arr1, arr2)\n",
    "    R = size(arr1)[1]\n",
    "    C = size(arr1)[2]\n",
    "    Ch = size(arr1)[3]+size(arr2)[3]\n",
    "    S = size(arr1)[4]\n",
    "    \n",
    "    arr1 = flatten(permutedims(arr1, [1,2,4,3]))\n",
    "    arr2 = flatten(permutedims(arr2, [1,2,4,3]))\n",
    "    out = reshape(cat1d(arr1,arr2),R,C,S,Ch)\n",
    "    out = permutedims(out,[1,2,4,3])\n",
    "    \n",
    "    return out\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function predict(w,x_in)\n",
    "    \n",
    "    # TODO:\n",
    "    # include batch norm: https://github.com/denizyuret/Knet.jl/blob/master/src/batchnorm.jl\n",
    "    \n",
    "    # contraction\n",
    "    #block 1\n",
    "    # 256x256x2 -> 256x256x64\n",
    "    conv_1_1 = relu.(conv4(w[1],x_in, padding = 1) .+ w[2]) # bock 1 convolution 1\n",
    "    # 256x256x64 -> 256x256x64 (conc with block 7)\n",
    "    conv_1_2 = relu.(conv4(w[3],conv_1_1, padding = 1) .+ w[4]) # block 1 convolution 2, incl max pooling\n",
    "    # 256-256-64 -> 128x128x64\n",
    "    pool_1 = pool(conv_1_2)\n",
    "    \n",
    "    # block 2\n",
    "    # 128x128x64 -> 128x128x128\n",
    "    conv_2_1 = relu.(conv4(w[5],pool_1, padding = 1) .+ w[6])\n",
    "    # 128x128x128 -> 128x128x128 (conc with block 6)\n",
    "    conv_2_2 = relu.(conv4(w[7],conv_2_1, padding = 1) .+ w[8])\n",
    "    # 128x128x128 -> 64x64x128\n",
    "    pool_2 = pool(conv_2_2)\n",
    "    \n",
    "    #block 3\n",
    "    # 64x64x128 -> 64x64x256\n",
    "    conv_3_1 = relu.(conv4(w[9],pool_2, padding = 1) .+ w[10])\n",
    "    #64x64x256 -> 64x64x256\n",
    "    conv_3_2 = relu.(conv4(w[11],conv_3_1, padding = 1) .+ w[12])\n",
    "    # 64x64x256 -> 32x32x256 (conc with block 5)\n",
    "    pool_3 = pool(conv_3_2)\n",
    "    \n",
    "    # bottleneck \n",
    "    # block 4\n",
    "    # 32x32x256 -> 32x32x512\n",
    "    conv_4_1 = relu.(conv4(w[13], pool_3, padding = 1) .+ w[14])\n",
    "    #32x32x512 -> 32x32x512\n",
    "    conv_4_2 = relu.(conv4(w[15], conv_4_1, padding = 1) .+ w[16])\n",
    "    \n",
    "    # upsampling\n",
    "    # block 5\n",
    "    # upsampling/\"deconvolution\": 32x32x512 -> 64x64x512\n",
    "    upsampling_kernel_5 = convert(KnetArray, bilinear(Float64,2,2,512,512))\n",
    "    upsampling_5 = deconv4(upsampling_kernel_5, conv_4_2, padding = 1,stride = 2)\n",
    "    # concatenation with conv_3_2: 64x64x512 -> 64x64x768\n",
    "    # conc_5 = convert(KnetArray,cat(convert(Array, upsampling_5), convert(Array, conv_3_2), dims = 3))\n",
    "    cat_5 = cat3d(upsampling_5,conv_3_2)\n",
    "    # 64x64x768 -> 64x64x256\n",
    "    conv_5_1 = relu.(conv4(w[17], cat_5, padding = 1) .+ w[18])\n",
    "    # 64x64x256-> 64x64x256\n",
    "    conv_5_2 = relu.(conv4(w[19], conv_5_1, padding = 1) .+ w[20])\n",
    "    \n",
    "    # block 6\n",
    "    # 64x64x256 -> 128x128x256\n",
    "    upsampling_kernel_6 = convert(KnetArray, bilinear(Float64,2,2,256,256))\n",
    "    upsampling_6 = deconv4(upsampling_kernel_6, conv_5_2, padding = 1,stride = 2) \n",
    "    # 128x128x256 -> 128x128x384\n",
    "    # conc_6 = convert(KnetArray,cat(convert(Array,upsampling_6), convert(Array,conv_2_2), dims = 3)) # with conv_2_2\n",
    "    cat_6 = cat3d(upsamling_6, conv_2_2)\n",
    "    #128x128x384 -> 128x128x128\n",
    "    conv_6_1 = relu.(conv4(w[21], cat_6, padding = 1) .+ w[22])\n",
    "    # 128x128x128 -> 128x128x128\n",
    "    conv_6_2 = relu.(conv4(w[23], conv_6_1, padding = 1) .+ w[24])\n",
    "    \n",
    "    # block 7\n",
    "    # 128x128x128 -> 256x256x128\n",
    "    upsampling_kernel_7 = convert(KnetArray, bilinear(Float64,2,2,128,128))\n",
    "    upsampling_7 = deconv4(upsampling_kernel_7, conv_6_2, padding = 1,stride = 2) \n",
    "    # 256x256x128 -> 256x256x192\n",
    "    # conc_7 = convert(KnetArray,cat(convert(Array, upsampling_7), convert(Array, conv_1_2), dims = 3))\n",
    "    cat_7 = cat3d(upsamling_7, conv_1_2)\n",
    "    # 256x256x192 -> 256x256x64\n",
    "    conv_7_1 = relu.(conv4(w[25], cat_7, padding = 1) .+ w[26])\n",
    "    # 256x256x64 -> 256x256x64\n",
    "    conv_7_2 = relu.(conv4(w[27], conv_7_1, padding = 1) .+ w[28])\n",
    "    # 256x256x64 -> 256x256x2 (1x1 convolution)\n",
    "    conv_7_3 = sigm.(conv4(w[29], conv_7_2).+ w[30])\n",
    "    \n",
    "    return conv_7_3\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function conv_layer_encoder(w, bn_moments, bn_params, x)\n",
    "    out = conv4(w[1], x, padding=1).+ w[2]\n",
    "    out = batchnorm(out, bn_moments[1], bn_params[1])\n",
    "    conv_1 = relu.(out)\n",
    "    \n",
    "    out = conv4(w[3], conv_1, padding=1) .+ w[4]\n",
    "    out = batchnorm(out, bn_moments[2], bn_params[2])\n",
    "    out = relu.(out)\n",
    "    pooled = pool(out)\n",
    "    \n",
    "    return conv_1, pooled\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conv_layer_decoder (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function conv_layer_decoder(w, bn_moments, bn_params, x_cat, x)\n",
    "    number_of_channels = size(x)[3]\n",
    "    upsampling_kernel = convert(KnetArray, bilinear(Float64,2,2,number_of_channels,number_of_channels))\n",
    "    out = deconv4(upsampling_kernel, x, padding = 1,stride = 2) \n",
    "    out = cat3d(out, x_cat)\n",
    "    \n",
    "    out = conv4(w[1], out, padding = 1) .+ w[2]\n",
    "    out = batchnorm(out, bn_moments[1], bn_params[1])\n",
    "    out = relu.(out)\n",
    "    \n",
    "    out = conv4(w[3], out, padding = 1) .+ w[4]\n",
    "    out = batchnorm(out, bn_moments[2], bn_params[2])\n",
    "    out = relu.(out)\n",
    "    \n",
    "    return out\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bottleneck (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function bottleneck(w, bn_moments, bn_params, x)\n",
    "    out = conv4(w[1], x, padding = 1) .+ w[2]\n",
    "    out = batchnorm(out, bn_moments[1], bn_params[1])\n",
    "    out = relu.(out)\n",
    "    out = conv4(w[3], x, padding = 1) .+ w[4]\n",
    "    out = batchnorm(out, bn_moments[2], bn_params[2])\n",
    "    out = relu.(out)\n",
    "    \n",
    "    return out\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function output_layer(w, x)\n",
    "    out = sigm.(conv4(w[1], x).+ w[2])\n",
    "    \n",
    "    return out\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function predict(w,bn_moments, bn_params,x_in)\n",
    "    # layer 1\n",
    "    conv_1, out = conv_layer_encoder(w[1:4], bn_moments[1:2], bn_params[1:2], x_in)\n",
    "    # layer 2\n",
    "    conv_2, out = conv_layer_encoder(w[5:8], bn_moments[3:4], bn_params[3:4], out)\n",
    "    #layer 3\n",
    "    conv_3, out = conv_layer_encoder(w[9:12], bn_moments[5:6], bn_params[5:6], out)\n",
    "    # layer 4 = bottleneck\n",
    "    # out = bottleneck(w[13:16], bn_moments[7:8], bn_params[7:8], out)\n",
    "    out = conv4(w[13], out, padding = 1) .+ w[14]\n",
    "    out = batchnorm(out, bn_moments[7], bn_params[7])\n",
    "    out = relu.(out)\n",
    "    out = conv4(w[15], x, padding = 1) .+ w[16]\n",
    "    out = batchnorm(out, bn_moments[8], bn_params[8])\n",
    "    out = relu.(out)\n",
    "    # layer 5\n",
    "    out = conv_layer_decoder(w[17:20], bn_moments[9:10], bn_params[9:10], conv_3, out)\n",
    "    # layer 6\n",
    "    out = conv_layer_decoder(w[21:24], bn_moments[11:12], bn_params[11:12], conv_2, out)\n",
    "    # layer 7\n",
    "    out = conv_layer_decoder(w[25:28], bn_moments[13:14], bn_params[13:14], conv_1, out)\n",
    "    out = output_layer(w[29:30], out)\n",
    "    \n",
    "    return out\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss\n",
    "NOT IMPLEMENTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dice loss\n",
    "loss(w, x, ygold, predict) = nll(predict(w, x), ygold);\n",
    "lossgradient = grad(loss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function flatten(array)\n",
    "    size_array = size(array)\n",
    "    length_flattened = 1\n",
    "    for dim = 1:ndims(array)\n",
    "        length_flattened = length_flattened * size_array[dim]\n",
    "    end\n",
    "    return flattened = reshape(array,length_flattened)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical cross-entropy\n",
    "function categorical_crossentropy_3d(y_true, y_pred):\n",
    "    epsilon = 1.0e-7\n",
    "    y_true_flatten = flatten(y_true)\n",
    "    y_pred_flatten = flatten(y_pred)\n",
    "    y_pred_flatten_log = log.(y_pred_flatten.+epsilon)\n",
    "    num_total_elements = sum(y_true_flatten) # number of positive voxels (gt 0/1 encoded)\n",
    "    cross_entropy = sum(y_true_flatten.*y_pred_flatten_log)\n",
    "    mean_cross_entropy = cross_entropy/(num_total_elements+epsilon)\n",
    "    return mean_cross_entropy\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train\n",
    "NOT IMPLEMENTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function train(w, dtrn, optim, predict; epochs=10)\n",
    "    \n",
    "    for epoch = 1:epochs\n",
    "        for (x, y) in dtrn\n",
    "            g = lossgradient(w, x, y, predict)\n",
    "            update!(w, g, optim)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim(w; lr=0.1) = optimizers(w, Sgd;  lr=lr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function report(epoch, w, dtrn, dtst, predict)\n",
    "    println((:epoch, epoch, :trn, accuracy(w, dtrn, predict), :tst, accuracy(w, dtst, predict)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w   = initweights(atype);\n",
    "opt = optim(w);\n",
    "\n",
    "if fast\n",
    "    train(w, dtrn, opt, predict; epochs=nepochs)\n",
    "else\n",
    "    for epoch = 1:nepochs\n",
    "        train(w, dtrn, opt, predict; epochs=1)\n",
    "        report(epoch, w, dtrn, dtst, predict)\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.1",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
