{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /Users/kathi/.julia/compiled/v1.0/Knet/f4vSz.ji for Knet [1902f260-5fb4-5aff-8c31-6271790ab950]\n",
      "└ @ Base loading.jl:1187\n",
      "WARNING: Method definition gcnode(AutoGrad.Node) in module AutoGrad at /Users/kathi/.julia/packages/AutoGrad/eAmjh/src/core.jl:38 overwritten in module Knet at /Users/kathi/.julia/packages/Knet/3lzCR/src/gcnode.jl:18.\n"
     ]
    }
   ],
   "source": [
    "using Knet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "not implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization of weights (w/o batchnorm)\n",
    "function init_model()\n",
    "    w =  map(KnetArray, Any[ xavier(Float64,3,3,2,64),  zeros(Float64,1,1,64,1), # conv_1_1\n",
    "            xavier(Float64,3,3,64,64), zeros(Float64,1,1,64,1), # conv_1_2\n",
    "            xavier(Float64,3,3,64,128), zeros(Float64,1,1,128,1), # conv_2_1\n",
    "            xavier(Float64,3,3,128,128), zeros(Float64,1,1,128,1) , # conv_2_2\n",
    "            xavier(Float64,3,3,128,256), zeros(Float64,1,1,256,1), # conv_3_1 \n",
    "            xavier(Float64,3,3,256,256), zeros(Float64,1,1,256,1), # conv_3_2\n",
    "            xavier(Float64,3,3,256,512), zeros(Float64,1,1,512,1), # conv_4_1 \n",
    "            xavier(Float64,3,3,512,512), zeros(Float64,1,1,512,1),  # conv_4_2\n",
    "            xavier(Float64,3,3,768,256), zeros(Float64,1,1,256,1), #conv_5_1\n",
    "            xavier(Float64,3,3,256,256), zeros(Float64,1,1,256,1), # conv_5_2\n",
    "            xavier(Float64,3,3,384,128), zeros(Float64,1,1,128,1), # conv_6_1\n",
    "            xavier(Float64,3,3,128,128), zeros(Float64,1,1,128,1), # conv_6_2\n",
    "            xavier(Float64,3,3,192,64), zeros(Float64,1,1,64,1), # conv_7_1\n",
    "            xavier(Float64,3,3,64,64), zeros(Float64,1,1,64,1), # conv_7_2\n",
    "            xavier(Float64,1,1,64,2), zeros(Float64,1,1,2,1)]); # conv_7_3\n",
    "    return w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization of weights (w/o batchnorm)\n",
    "function init_model(depth, max_channels)\n",
    "    # initialize w\n",
    "    for layer in range(1,depth)\n",
    "        \n",
    "    w =  map(atype, Any[ xavier(Float64,3,3,2,64),  zeros(Float64,1,1,64,1), # conv_1_1\n",
    "            xavier(Float64,3,3,64,64), zeros(Float64,1,1,64,1), # conv_1_2\n",
    "            xavier(Float64,3,3,64,128), zeros(Float64,1,1,128,1), # conv_2_1\n",
    "            xavier(Float64,3,3,128,128), zeros(Float64,1,1,128,1) , # conv_2_2\n",
    "            xavier(Float64,3,3,128,256), zeros(Float64,1,1,256,1), # conv_3_1 \n",
    "            xavier(Float64,3,3,256,256), zeros(Float64,1,1,256,1), # conv_3_2\n",
    "            xavier(Float64,3,3,256,512), zeros(Float64,1,1,512,1), # conv_4_1 \n",
    "            xavier(Float64,3,3,512,512), zeros(Float64,1,1,512,1),  # conv_4_2\n",
    "            xavier(Float64,3,3,768,256), zeros(Float64,1,1,256,1), #conv_5_1\n",
    "            xavier(Float64,3,3,256,256), zeros(Float64,1,1,256,1), # conv_5_2\n",
    "            xavier(Float64,3,3,384,128), zeros(Float64,1,1,128,1), # conv_6_1\n",
    "            xavier(Float64,3,3,128,128), zeros(Float64,1,1,128,1), # conv_6_2\n",
    "            xavier(Float64,3,3,192,64), zeros(Float64,1,1,64,1), # conv_7_1\n",
    "            xavier(Float64,3,3,64,64), zeros(Float64,1,1,64,1), # conv_7_2\n",
    "            xavier(Float64,1,1,64,2), zeros(Float64,1,1,2,1)]); # conv_7_3\n",
    "    return w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization of weights (w/ batchnorm)\n",
    "function init_model_bn()\n",
    "    # include m (moments for batchnorm)\n",
    "    m = Any[bnmoments() for i = 1:n]# n = how often do we use BN?\n",
    "    \n",
    "    w =  map(atype, Any[ xavier(Float64,3,3,2,64),  zeros(Float64,1,1,64,1), # conv_1_1\n",
    "            xavier(Float64,3,3,64,64), zeros(Float64,1,1,64,1), # conv_1_2\n",
    "            xavier(Float64,3,3,64,128), zeros(Float64,1,1,128,1), # conv_2_1\n",
    "            xavier(Float64,3,3,128,128), zeros(Float64,1,1,128,1) , # conv_2_2\n",
    "            xavier(Float64,3,3,128,256), zeros(Float64,1,1,256,1), # conv_3_1 \n",
    "            xavier(Float64,3,3,256,256), zeros(Float64,1,1,256,1), # conv_3_2\n",
    "            xavier(Float64,3,3,256,512), zeros(Float64,1,1,512,1), # conv_4_1 \n",
    "            xavier(Float64,3,3,512,512), zeros(Float64,1,1,512,1),  # conv_4_2\n",
    "            xavier(Float64,3,3,768,256), zeros(Float64,1,1,256,1), #conv_5_1\n",
    "            xavier(Float64,3,3,256,256), zeros(Float64,1,1,256,1), # conv_5_2\n",
    "            xavier(Float64,3,3,384,128), zeros(Float64,1,1,128,1), # conv_6_1\n",
    "            xavier(Float64,3,3,128,128), zeros(Float64,1,1,128,1), # conv_6_2\n",
    "            xavier(Float64,3,3,192,64), zeros(Float64,1,1,64,1), # conv_7_1\n",
    "            xavier(Float64,3,3,64,64), zeros(Float64,1,1,64,1), # conv_7_2\n",
    "            xavier(Float64,1,1,64,2), zeros(Float64,1,1,2,1)]); # conv_7_3\n",
    "    return w, m\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init_model (generic function with 6 methods)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function init_model(n_input_channels=1, n_output_channels=2, depth=4, max_channels=512, kernel_size=3)\n",
    "    w = Any[]\n",
    "    # 1st layer\n",
    "    # convolution\n",
    "    push!(w,xavier(Float64,kernel_size,kernel_size,n_input_channels,Int64(max_channels/(2^(depth-1)))))\n",
    "    # bias\n",
    "    push!(w,zeros(Float64,1,1,Int64(max_channels/(2^(depth-1)))))\n",
    "    \n",
    "    # 2nd up to and including bottleneck\n",
    "    for layer in 2:depth\n",
    "        print(layer)\n",
    "       push!(w,xavier(Float64,kernel_size,kernel_size,Int64(max_channels/(2^(depth-layer+1))),Int64(max_channels/(2^(depth-layer))))) \n",
    "        push!(w, zeros(Float64,1,1,Int64(max_channels/(2^(depth-layer)))))\n",
    "    end\n",
    "    return w\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model\n",
    "IMPLEMENTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching rand(::Type{Float64}, ::Int64, ::Int64, ::Int64, ::Float64)\nClosest candidates are:\n  rand(::Type{X}, ::Integer, !Matched::Integer...) where X at /Users/osx/buildbot/slave/package_osx64/build/usr/share/julia/stdlib/v1.0/Random/src/Random.jl:259\n  rand(::Any, ::Integer, !Matched::Integer...) at /Users/osx/buildbot/slave/package_osx64/build/usr/share/julia/stdlib/v1.0/Random/src/Random.jl:247\n  rand(!Matched::Random.AbstractRNG, !Matched::Integer...) at /Users/osx/buildbot/slave/package_osx64/build/usr/share/julia/stdlib/v1.0/Random/src/Random.jl:240\n  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching rand(::Type{Float64}, ::Int64, ::Int64, ::Int64, ::Float64)\nClosest candidates are:\n  rand(::Type{X}, ::Integer, !Matched::Integer...) where X at /Users/osx/buildbot/slave/package_osx64/build/usr/share/julia/stdlib/v1.0/Random/src/Random.jl:259\n  rand(::Any, ::Integer, !Matched::Integer...) at /Users/osx/buildbot/slave/package_osx64/build/usr/share/julia/stdlib/v1.0/Random/src/Random.jl:247\n  rand(!Matched::Random.AbstractRNG, !Matched::Integer...) at /Users/osx/buildbot/slave/package_osx64/build/usr/share/julia/stdlib/v1.0/Random/src/Random.jl:240\n  ...",
      "",
      "Stacktrace:",
      " [1] xavier(::Type, ::Vararg{Any,N} where N) at /Users/kathi/.julia/packages/Knet/3lzCR/src/distributions.jl:29",
      " [2] init_model(::Int64, ::Int64, ::Int64, ::Int64, ::Int64) at ./In[7]:4",
      " [3] init_model() at ./In[7]:2",
      " [4] top-level scope at In[8]:1"
     ]
    }
   ],
   "source": [
    "w = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 2\n",
    "x != 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat_3 (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# auxilliary (concatenation of 4d tensors along 3rd dim)\n",
    "function cat_3(arr1,arr2)\n",
    "    size_arr1 = size(arr1)\n",
    "    size_arr2 = size(arr2)\n",
    "    # check dims\n",
    "    if size_arr1[1]!=size_arr2[1]||size_arr1[2]!=size_arr2[2]||size_arr1[4]!=size_arr2[4]\n",
    "        print(\"dimension missmatch cat\")\n",
    "    # concatenate\n",
    "    else\n",
    "        arr1_reshaped = reshape(arr1,size_arr1[1]*size_arr1[2]*size_arr1[3]*size_arr1[4],1)\n",
    "        arr2_reshaped = reshape(arr2,size_arr2[1]*size_arr2[2]*size_arr2[3]*size_arr2[4],1)\n",
    "        cat_arr = cat(arr1_reshaped, arr2_reshaped, dims = 2)\n",
    "        cat_arr = reshape(cat_arr, size_arr1[1], size_arr1[2], size_arr1[3]+size_arr2[3],size_arr1[4])\n",
    "    end\n",
    "    return cat_arr\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2×4×2 Array{Float64,4}:\n",
       "[:, :, 1, 1] =\n",
       " 1.0  1.0\n",
       " 1.0  1.0\n",
       "\n",
       "[:, :, 2, 1] =\n",
       " 1.0  1.0\n",
       " 1.0  1.0\n",
       "\n",
       "[:, :, 3, 1] =\n",
       " 1.0  1.0\n",
       " 1.0  1.0\n",
       "\n",
       "[:, :, 4, 1] =\n",
       " 1.0  1.0\n",
       " 1.0  1.0\n",
       "\n",
       "[:, :, 1, 2] =\n",
       " 0.0  0.0\n",
       " 0.0  0.0\n",
       "\n",
       "[:, :, 2, 2] =\n",
       " 0.0  0.0\n",
       " 0.0  0.0\n",
       "\n",
       "[:, :, 3, 2] =\n",
       " 0.0  0.0\n",
       " 0.0  0.0\n",
       "\n",
       "[:, :, 4, 2] =\n",
       " 0.0  0.0\n",
       " 0.0  0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ones(2,2,2,2)\n",
    "y = zeros(2,2,2,2)\n",
    "cat_3(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Foo\n",
    "           bar\n",
    "           baz\n",
    "       end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function predict(w,x_in)\n",
    "    \n",
    "    # TODO:\n",
    "    # include batch norm: https://github.com/denizyuret/Knet.jl/blob/master/src/batchnorm.jl\n",
    "    \n",
    "    # contraction\n",
    "    #block 1\n",
    "    # 256x256x2 -> 256x256x64\n",
    "    conv_1_1 = relu.(conv4(w[1],x_in, padding = 1) .+ w[2]) # bock 1 convolution 1\n",
    "    # 256x256x64 -> 256x256x64 (conc with block 7)\n",
    "    conv_1_2 = relu.(conv4(w[3],conv_1_1, padding = 1) .+ w[4]) # block 1 convolution 2, incl max pooling\n",
    "    # 256-256-64 -> 128x128x64\n",
    "    pool_1 = pool(conv_1_2)\n",
    "    \n",
    "    # block 2\n",
    "    # 128x128x64 -> 128x128x128\n",
    "    conv_2_1 = relu.(conv4(w[5],pool_1, padding = 1) .+ w[6])\n",
    "    # 128x128x128 -> 128x128x128 (conc with block 6)\n",
    "    conv_2_2 = relu.(conv4(w[7],conv_2_1, padding = 1) .+ w[8])\n",
    "    # 128x128x128 -> 64x64x128\n",
    "    pool_2 = pool(conv_2_2)\n",
    "    \n",
    "    #block 3\n",
    "    # 64x64x128 -> 64x64x256\n",
    "    conv_3_1 = relu.(conv4(w[9],pool_2, padding = 1) .+ w[10])\n",
    "    #64x64x256 -> 64x64x256\n",
    "    conv_3_2 = relu.(conv4(w[11],conv_3_1, padding = 1) .+ w[12])\n",
    "    # 64x64x256 -> 32x32x256 (conc with block 5)\n",
    "    pool_3 = pool(conv_3_2)\n",
    "    \n",
    "    # bottleneck \n",
    "    # block 4\n",
    "    # 32x32x256 -> 32x32x512\n",
    "    conv_4_1 = relu.(conv4(w[13], pool_3, padding = 1) .+ w[14])\n",
    "    #32x32x512 -> 32x32x512\n",
    "    conv_4_2 = relu.(conv4(w[15], conv_4_1, padding = 1) .+ w[16])\n",
    "    \n",
    "    # upsampling\n",
    "    # block 5\n",
    "    # upsampling/\"deconvolution\": 32x32x512 -> 64x64x512\n",
    "    upsampling_kernel_5 = convert(KnetArray, bilinear(Float64,2,2,512,512))\n",
    "    upsampling_5 = deconv4(upsampling_kernel_5, conv_4_2, padding = 1,stride = 2)\n",
    "    # concatenation with conv_3_2: 64x64x512 -> 64x64x768\n",
    "    conc_5 = convert(KnetArray,cat(convert(Array, upsampling_5), convert(Array, conv_3_2), dims = 3))\n",
    "    # 64x64x768 -> 64x64x256\n",
    "    conv_5_1 = relu.(conv4(w[17], conc_5, padding = 1) .+ w[18])\n",
    "    # 64x64x256-> 64x64x256\n",
    "    conv_5_2 = relu.(conv4(w[19], conv_5_1, padding = 1) .+ w[20])\n",
    "    \n",
    "    # block 6\n",
    "    # 64x64x256 -> 128x128x256\n",
    "    upsampling_kernel_6 = convert(KnetArray, bilinear(Float64,2,2,256,256))\n",
    "    upsampling_6 = deconv4(upsampling_kernel_6, conv_5_2, padding = 1,stride = 2) \n",
    "    # 128x128x256 -> 128x128x384\n",
    "    conc_6 = convert(KnetArray,cat(convert(Array,upsampling_6), convert(Array,conv_2_2), dims = 3)) # with conv_2_2\n",
    "    #128x128x384 -> 128x128x128\n",
    "    conv_6_1 = relu.(conv4(w[21], conc_6, padding = 1) .+ w[22])\n",
    "    # 128x128x128 -> 128x128x128\n",
    "    conv_6_2 = relu.(conv4(w[23], conv_6_1, padding = 1) .+ w[24])\n",
    "    \n",
    "    # block 7\n",
    "    # 128x128x128 -> 256x256x128\n",
    "    upsampling_kernel_7 = convert(KnetArray, bilinear(Float64,2,2,128,128))\n",
    "    upsampling_7 = deconv4(upsampling_kernel_7, conv_6_2, padding = 1,stride = 2) \n",
    "    # 256x256x128 -> 256x256x192\n",
    "    conc_7 = convert(KnetArray,cat(convert(Array, upsampling_7), convert(Array, conv_1_2), dims = 3))\n",
    "    # 256x256x192 -> 256x256x64\n",
    "    conv_7_1 = relu.(conv4(w[25], conc_7, padding = 1) .+ w[26])\n",
    "    # 256x256x64 -> 256x256x64\n",
    "    conv_7_2 = relu.(conv4(w[27], conv_7_1, padding = 1) .+ w[28])\n",
    "    # 256x256x64 -> 256x256x2 (1x1 convolution)\n",
    "    conv_7_3 = sigm.(conv4(w[29], conv_7_2).+ w[30])\n",
    "    \n",
    "    return conv_7_3\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss\n",
    "NOT IMPLEMENTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dice loss\n",
    "loss(w, x, ygold, predict) = nll(predict(w, x), ygold);\n",
    "lossgradient = grad(loss);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train\n",
    "NOT IMPLEMENTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function train(w, dtrn, optim, predict; epochs=10)\n",
    "    \n",
    "    for epoch = 1:epochs\n",
    "        for (x, y) in dtrn\n",
    "            g = lossgradient(w, x, y, predict)\n",
    "            update!(w, g, optim)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim(w; lr=0.1) = optimizers(w, Sgd;  lr=lr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function report(epoch, w, dtrn, dtst, predict)\n",
    "    println((:epoch, epoch, :trn, accuracy(w, dtrn, predict), :tst, accuracy(w, dtst, predict)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w   = initweights(atype);\n",
    "opt = optim(w);\n",
    "\n",
    "if fast\n",
    "    train(w, dtrn, opt, predict; epochs=nepochs)\n",
    "else\n",
    "    for epoch = 1:nepochs\n",
    "        train(w, dtrn, opt, predict; epochs=1)\n",
    "        report(epoch, w, dtrn, dtst, predict)\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.1",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
